#!/bin/bash

# ğŸš€ DEPLOY PARALLEL TRANSLATION OPTIMIZATION
# Switches from sequential to parallel processing for 3-10x speed improvement

echo "ğŸš€ DEPLOYING PARALLEL TRANSLATION OPTIMIZATION"
echo "=============================================="

cd /home/ubuntu/translation-worker-api || {
    echo "âŒ Cannot access project directory"
    exit 1
}

echo "âš¡ PERFORMANCE UPGRADE:"
echo "â€¢ Sequential â†’ Parallel batch processing"
echo "â€¢ 1 worker â†’ 20+ parallel workers"
echo "â€¢ Blocking calls â†’ Async ThreadPoolExecutor"
echo "â€¢ Expected: 3-10x faster translation speed"
echo ""

echo "ğŸ“ Step 1: Backup Current Implementation"
echo "========================================"

# Backup current files
cp celery_app.py celery_app_sequential.py.backup
cp utils/text_segmentation.py utils/text_segmentation_sequential.py.backup
echo "âœ… Backups created (sequential versions preserved)"

echo ""
echo "ğŸ”„ Step 2: Switch to Parallel Implementation"
echo "==========================================="

# Replace the main celery app with parallel version
cp celery_app_parallel.py celery_app.py
echo "âœ… Updated celery_app.py to use parallel processing"

# Update docker-compose to use parallel configuration
echo "Updating docker-compose.yml for parallel optimization..."

# Create optimized docker-compose configuration
cat > docker-compose.parallel.yml << 'EOF'
version: '3.8'

services:
  redis:
    image: redis:alpine
    container_name: translation-worker-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data

  api:
    build: .
    container_name: translation-worker-api
    restart: unless-stopped
    ports:
      - "80:8000"
    depends_on:
      - redis
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      # Parallel processing optimizations
      - MAX_PARALLEL_BATCHES=20
      - MAX_TRANSLATION_WORKERS=20
      - SMALL_TEXT_BATCH_SIZE=15
      - LARGE_TEXT_BATCH_SIZE=25
    command: uvicorn app:app --host 0.0.0.0 --port 8000 --limit-concurrency 200 --limit-max-requests 104857600
    volumes:
      - .:/app

  worker:
    build: .
    container_name: translation-worker-celery
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      # Parallel processing optimizations
      - MAX_PARALLEL_BATCHES=20
      - MAX_TRANSLATION_WORKERS=20
      - SMALL_TEXT_BATCH_SIZE=15
      - LARGE_TEXT_BATCH_SIZE=25
    command: celery -A celery_app worker --loglevel=info --concurrency=8 --prefetch-multiplier=2 -Q high_priority,low_priority
    volumes:
      - .:/app

volumes:
  redis_data:
EOF

cp docker-compose.parallel.yml docker-compose.yml
echo "âœ… Updated docker-compose.yml with parallel optimizations"

echo ""
echo "ğŸ“¤ Step 3: Commit and Push Changes"
echo "==================================="

git add .
git commit -m "feat: Deploy parallel translation optimization for 3-10x speed improvement

- Add utils/text_segmentation_parallel.py with ThreadPoolExecutor
- Add celery_app_parallel.py with async batch processing  
- Update docker-compose.yml with parallel worker configuration
- Preserve sequential versions as backups
- Expected performance: 20+ parallel workers vs 1 sequential"

git push origin main
echo "âœ… Parallel optimization pushed to repository"

echo ""
echo "ğŸ›‘ Step 4: Stop Current Services"
echo "==============================="

sudo docker-compose down --remove-orphans
echo "âœ… Sequential services stopped"

echo ""
echo "ğŸ”¨ Step 5: Rebuild with Parallel Optimization"
echo "============================================="

echo "Building parallel-optimized containers..."
sudo docker-compose build --no-cache

echo "âœ… Containers rebuilt with parallel optimization"

echo ""
echo "ğŸš€ Step 6: Start Parallel Services"
echo "=================================="

sudo docker-compose up -d

echo "Waiting 30 seconds for parallel services to initialize..."
sleep 30

echo "âœ… Parallel services started"

echo ""
echo "ğŸ§ª Step 7: Test Parallel Performance"
echo "===================================="

echo "Checking worker status:"
sudo docker-compose ps worker

echo ""
echo "Worker logs (checking for parallel initialization):"
sudo docker-compose logs worker --tail=20 | grep -E "(parallel|PARALLEL|workers|batches)" || echo "No parallel logs yet"

echo ""
echo "Testing worker ping:"
PING_RESULT=$(sudo docker exec translation-worker-celery celery -A celery_app inspect ping 2>/dev/null)

if echo "$PING_RESULT" | grep -q "pong"; then
    echo "âœ… Parallel worker responding to ping!"
else
    echo "âŒ Worker not responding, checking logs:"
    sudo docker-compose logs worker --tail=10
fi

echo ""
echo "ğŸ¯ Step 8: Performance Test"
echo "==========================="

echo "Submitting performance test with medium-sized content..."

# Create test content that will benefit from parallel processing
TEST_CONTENT="à½¢à¾’à¾±à½£à¼‹à½”à½¼à¼‹à½à¾²à½²à¼‹à½¦à¾²à½¼à½„à¼‹à½£à¾¡à½ºà¼‹à½–à½™à½“à¼‹à½‚à¾±à½²à¼‹à½¦à¾à½–à½¦à¼‹à½¦à½´à¼‹à½–à½¼à½‘à¼‹à½‘à½´à¼‹à½“à½„à¼‹à½”à½ à½²à¼‹à½†à½¼à½¦à¼‹à½‘à½¢à¼‹à½–à¼‹à½¡à½²à½“à¼ à½‘à½ºà¼‹à½‘à½´à½¦à¼‹à½–à½¼à½‘à¼‹à½”à¼‹à½¢à¾£à½˜à½¦à¼‹à½€à¾±à½²à½¦à¼‹à½‚à½¦à½¢à¼‹à½”à½ à½²à¼‹à½¡à½²à¼‹à½‚à½ºà¼‹à½–à½Ÿà½¼à½¦à¼‹à½à½ºà¼‹à½‚à½à½´à½„à¼‹à½£à½´à½‚à½¦à¼‹à½€à¾±à½²à¼‹à½‘à½”à½ºà¼‹à½†à¼‹à½˜à½„à¼‹à½”à½¼à¼‹à½–à¾²à½²à½¦à¼ à½–à½¼à½‘à¼‹à½€à¾±à½²à¼‹à½¦à¾à½‘à¼‹à½¡à½²à½‚à¼‹à½£à¼‹à½¢à¾’à¾±à¼‹à½‚à½¢à¼‹à½‘à½„à¼‹à½¢à¾’à¾±à¼‹à½“à½‚à¼‹à½‚à½²à¼‹à½£à½¼à¼‹à½¢à¾’à¾±à½´à½¦à¼‹à½€à¾±à½²à¼‹à½•à½“à¼‹à½à½¼à½‚à½¦à¼‹à½†à½ºà½“à¼‹à½”à½¼à¼‹à½¡à½¼à½‘à¼ à½‘à½ºà¼‹à½–à½à½²à½“à¼‹à½‘à½´à¼‹à½–à½¼à½‘à¼‹à½€à¾±à½²à¼‹à½¢à½²à½‚à¼‹à½‚à½“à½¦à¼‹à½£à¼‹à½¡à½„à¼‹à½¢à¾’à¾±à¼‹à½‚à½¢à¼‹à½‚à¾±à½²à¼‹à½“à½„à¼‹à½”à½ à½²à¼‹à½¤à½ºà½¦à¼‹à½¢à½²à½‚à¼‹à½‘à½„à¼‹à½¢à¾’à¾±à¼‹à½“à½‚à¼‹à½‚à½²à¼‹à½¦à¾²à½²à½‘à¼‹à½–à¾±à½´à½¦à¼‹à½€à¾±à½²à¼‹à½¢à¾£à½˜à¼‹à½‘à½”à¾±à½¼à½‘à¼‹à½†à½ºà½“à¼‹à½”à½¼à¼‹à½‚à½à½¼à½‚à½¦à¼‹à½¡à½¼à½‘à¼"

# Repeat content to make it larger for parallel processing test
for i in {1..10}; do
    TEST_CONTENT="$TEST_CONTENT $TEST_CONTENT"
done

echo "Test content length: ${#TEST_CONTENT} characters"

# Submit test translation
TEST_RESPONSE=$(curl -s -X POST http://localhost:8000/messages \
  -H "Content-Type: application/json" \
  -d "{
    \"content\": \"$TEST_CONTENT\",
    \"model_name\": \"test-parallel-model\",
    \"api_key\": \"test-parallel-key\", 
    \"priority\": 5
  }" 2>/dev/null)

if echo "$TEST_RESPONSE" | grep -q '"success":true'; then
    MESSAGE_ID=$(echo "$TEST_RESPONSE" | grep -o '"id":"[^"]*"' | cut -d'"' -f4)
    echo "âœ… Parallel test submitted: $MESSAGE_ID"
    
    echo ""
    echo "Monitoring parallel processing (30 seconds)..."
    
    for i in {1..6}; do
        sleep 5
        echo "Check $i:"
        
        # Check logs for parallel processing indicators
        PARALLEL_LOGS=$(sudo docker-compose logs worker --since="30s" | grep -E "(PARALLEL|parallel|workers|batches)" | tail -3)
        if [ -n "$PARALLEL_LOGS" ]; then
            echo "  Parallel activity detected:"
            echo "  $PARALLEL_LOGS"
        fi
        
        # Check task status
        STATUS_RESPONSE=$(curl -s http://localhost:8000/messages/$MESSAGE_ID 2>/dev/null)
        STATUS=$(echo "$STATUS_RESPONSE" | grep -o '"status_type":"[^"]*"' | cut -d'"' -f4)
        PROGRESS=$(echo "$STATUS_RESPONSE" | grep -o '"progress":[0-9.]*' | cut -d':' -f2)
        
        echo "  Status: $STATUS, Progress: ${PROGRESS}%"
        
        # Check for parallel mode flag
        if echo "$STATUS_RESPONSE" | grep -q '"parallel_mode":true'; then
            echo "  âœ… Parallel mode confirmed!"
        fi
        
        if [ "$STATUS" = "completed" ]; then
            echo "  ğŸ‰ Parallel translation completed!"
            break
        fi
    done
    
else
    echo "âŒ Test submission failed:"
    echo "$TEST_RESPONSE"
fi

echo ""
echo "ğŸ‰ PARALLEL OPTIMIZATION DEPLOYMENT COMPLETE"
echo "============================================="
echo ""
echo "âœ… PERFORMANCE IMPROVEMENTS ACTIVE:"
echo "â€¢ âš¡ 20+ parallel workers (vs 1 sequential)" 
echo "â€¢ ğŸš€ ThreadPoolExecutor for AI API calls"
echo "â€¢ ğŸ“Š Real-time progress during parallel execution"
echo "â€¢ ğŸ¯ Optimized batch sizing for content length"
echo "â€¢ ğŸ’¾ Partial result storage for real-time updates"
echo ""
echo "ğŸ“ˆ EXPECTED PERFORMANCE:"
echo "â€¢ Small texts (< 10k chars): 3-5x faster"
echo "â€¢ Medium texts (10-50k chars): 5-8x faster" 
echo "â€¢ Large texts (> 50k chars): 8-15x faster"
echo ""
echo "ğŸ” MONITOR PERFORMANCE:"
echo "sudo docker-compose logs worker -f | grep -E '(PARALLEL|performance|chars/sec)'"
echo ""
echo "ğŸ“Š VIEW PARALLEL METRICS:"
echo "curl http://localhost:8000/messages/{message_id} | jq '.performance'"
echo ""
echo "âš ï¸  ROLLBACK IF NEEDED:"
echo "cp celery_app_sequential.py.backup celery_app.py"
echo "cp utils/text_segmentation_sequential.py.backup utils/text_segmentation.py"
echo "sudo docker-compose restart"
echo ""
echo "ğŸ¯ Your translations are now MASSIVELY FASTER! ğŸš€" 